# í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬
# pip install -r requirements.txt

# import os
# from langchain_upstage import UpstageDocumentParseLoader, UpstageEmbeddings
# from langchain.text_splitter import RecursiveCharacterTextSplitter
# from langchain_chroma import Chroma
# from langchain.docstore.document import Document

# # API í‚¤ ì„¤ì •
# os.environ["OPENAI_API_KEY"] = "your-openai-api-key"
# os.environ["UPSTAGE_API_KEY"] = "up_p4zbJL1uBqSwlEs3739EZ9AQpeWWOh"

# # ì²˜ë¦¬í•  PDF ëª©ë¡ (ì´ë¦„ê³¼ íŒŒì¼ ê²½ë¡œ)
# pdf_list = [
#     {"game": "ì¹´íƒ„", "file": "pdfs/katan.pdf"},
#     {"game": "ìŠ¤í”Œë Œë”", "file": "pdfs/splendor.pdf"},
#     # ë” ì¶”ê°€í•˜ê³  ì‹¶ìœ¼ë©´ ì—¬ê¸°ì— game/file ê³„ì† ì¶”ê°€ë§Œ í•˜ë©´ ë¨!
# ]

# # ê³µí†µ ì„¤ì •
# text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
# embedding = UpstageEmbeddings(model="solar-embedding-1-large")
# persist_dir = "chroma_db"  # ì˜êµ¬ ì €ì¥ë  ë””ë ‰í† ë¦¬

# # Chroma DB ì´ˆê¸°í™” (ê¸°ì¡´ DB ìœ ì§€ + ì¶”ê°€ ì €ì¥ìš©)
# vectorstore = Chroma(
#     persist_directory=persist_dir,
#     embedding_function=embedding
# )

# # ë°˜ë³µ ì²˜ë¦¬
# for entry in pdf_list:
#     game_name = entry["game"]
#     file_path = entry["file"]

#     print(f"\nğŸ“¥ ì²˜ë¦¬ ì¤‘: {game_name} ({file_path})")

#     try:
#         # 1. ë¬¸ì„œ íŒŒì‹±
#         loader = UpstageDocumentParseLoader(
#             file_path=file_path,
#             output_format='html',
#             coordinates=False
#         )
#         parsed_docs = loader.load()

#         # 2. ë©”íƒ€ë°ì´í„° ì¶”ê°€
#         docs = [
#             Document(
#                 page_content=doc.page_content,
#                 metadata={"game": game_name}
#             )
#             for doc in parsed_docs
#         ]

#         # 3. ë¬¸ì„œ ë¶„í• 
#         chunks = text_splitter.split_documents(docs)

#         # 4. ì„ë² ë”© + ë²¡í„°DB ì €ì¥
#         vectorstore.add_documents(chunks)

#         print(f"ì €ì¥ ì™„ë£Œ: {game_name} ({len(chunks)} chunks)")

#     except Exception as e:
#         print(f"ì˜¤ë¥˜ ë°œìƒ: {game_name} ì²˜ë¦¬ ì‹¤íŒ¨ - {str(e)}")

# # ë§ˆì§€ë§‰ì— DB ì €ì¥ ì™„ë£Œ
# # vectorstore._client.persist() # ì €ì¥í•˜ëŠ” ì½”ë“œê°€ í•„ìš” ì—†ì–´ì§....
# print("\nğŸ“¦ ëª¨ë“  ê²Œì„ ë£°ì´ ë²¡í„° DBì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")






# ------------------------------------------- ì•„ë˜ëŠ” Pinecone version ì…ë‹ˆë‹¤ -------------------------------------------

import os
from dotenv import load_dotenv
from pinecone import Pinecone
from langchain_upstage import UpstageDocumentParseLoader, UpstageEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_pinecone import PineconeVectorStore
from langchain.docstore.document import Document

# .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# í™˜ê²½ë³€ìˆ˜ ê°€ì ¸ì˜¤ê¸°
openai_key = os.getenv("OPENAI_API_KEY")
upstage_key = os.getenv("UPSTAGE_API_KEY")
pinecone_key = os.getenv("PINECONE_API_KEY")

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (ë˜ëŠ” .envë¡œ ê´€ë¦¬ ê°€ëŠ¥)
os.environ["OPENAI_API_KEY"] = openai_key
os.environ["UPSTAGE_API_KEY"] = upstage_key
os.environ["PINECONE_API_KEY"] = pinecone_key

# Pinecone í´ë¼ì´ì–¸íŠ¸ ìƒì„± (init ëŒ€ì‹ )
pc = Pinecone(api_key=os.environ["PINECONE_API_KEY"])

# ì¸ë±ìŠ¤ ì´ë¦„
index_name = "boardgame-rag"

# PDF ëª©ë¡ ì •ì˜
pdf_list = [
    {"game": "í…ŒìŠ¤íŠ¸", "file": "pdfs/test.pdf", "namespace": "test"},
]

# ê³µí†µ ì„¤ì •
text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
embedding = UpstageEmbeddings(model="solar-embedding-1-large")

# PDF ì²˜ë¦¬ ë£¨í”„
for entry in pdf_list:
    game_name = entry["game"]
    file_path = entry["file"]
    namespace = entry["namespace"]

    print(f"\nğŸ“¥ ì²˜ë¦¬ ì¤‘: {game_name} ({file_path})")

    try:
        # 1. ë¬¸ì„œ íŒŒì‹±
        loader = UpstageDocumentParseLoader(
            file_path=file_path,
            output_format='html',
            coordinates=False
        )
        parsed_docs = loader.load()

        for doc in parsed_docs:
            print(doc.page_content[:500])  # ì•ë¶€ë¶„ ì¼ë¶€ ì¶œë ¥

        # 2. ë©”íƒ€ë°ì´í„° ì¶”ê°€
        docs = [
            Document(
                page_content=doc.page_content,
                metadata={"game": game_name}
            )
            for doc in parsed_docs
        ]

        # 3. ë¬¸ì„œ ë¶„í• 
        chunks = text_splitter.split_documents(docs)

        # 4. Pineconeì— ë²¡í„° ì €ì¥
        vectorstore = PineconeVectorStore.from_documents(
            documents=chunks,
            embedding=embedding,
            index_name=index_name,
            namespace=namespace
        )

        print(f"âœ… ì €ì¥ ì™„ë£Œ: {game_name} ({len(chunks)} chunks)")

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {game_name} ì²˜ë¦¬ ì‹¤íŒ¨ - {str(e)}")

print("\nğŸ“¦ ëª¨ë“  ê²Œì„ ë£°ì´ Pineconeì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")